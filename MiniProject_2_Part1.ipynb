{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4JY6VI7Uc8it"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer  \n",
        "from string import digits \n",
        "import numpy as np\n",
        "import operator\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swifter\n",
        "import swifter"
      ],
      "metadata": {
        "id": "ofgxqKTgY0B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnYJYZNfuAwP"
      },
      "outputs": [],
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JNgS3skLdBOm"
      },
      "outputs": [],
      "source": [
        "#Funtion to rename columns and remove the index column\n",
        "def rename_cols(dataset):\n",
        "    ds_new = dataset.rename(columns = {0:\"Target_Word\", 1:\"Sense_ID\", 2:\"Sentence\"})\n",
        "    ds_new = ds_new.reset_index(drop=True)\n",
        "    return ds_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L2MJDSIDdFmf"
      },
      "outputs": [],
      "source": [
        "#Function to clean the given sentence like removing punctuation and digits and, convert to lowercase \n",
        "def clean(sent):\n",
        "    to_remove = string.punctuation.replace('%', '')\n",
        "    sent = sent.lower()\n",
        "    sent = sent.translate(str.maketrans('', '', to_remove ))\n",
        "    to_remove_digits = str.maketrans('', '', digits) \n",
        "    sent = sent.translate(to_remove_digits)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RsbQeYrydHdM"
      },
      "outputs": [],
      "source": [
        "#Function to return list of [pos, lemma of word] for each word in a given sentence\n",
        "def get_pos_wordnet(sentence):\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    list_words = sentence\n",
        "    return_list = []\n",
        "    for i in range (len(list_words)):\n",
        "        # get the POS tag of the word\n",
        "        tag = nltk.pos_tag(list_words)[i][1][0].upper() \n",
        "        tag_dict = {\"J\": wordnet.ADJ,\n",
        "                    \"N\": wordnet.NOUN,\n",
        "                    \"V\": wordnet.VERB,\n",
        "                    \"R\": wordnet.ADV}\n",
        "        final_tag = tag_dict.get(tag, wordnet.NOUN) # default is Noun\n",
        "        lemma_word = lemmatizer.lemmatize(list_words[i],final_tag) # get lemma of the word\n",
        "        return_list.append([final_tag,lemma_word]) #returns POS and lemma of word\n",
        "    return return_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gQ2mhjOWdk1U"
      },
      "outputs": [],
      "source": [
        "#Fetching data from csv files\n",
        "d_train = pd.read_csv (r'train.data',header=None,delimiter = \"|\")\n",
        "d_train = d_train.reset_index()\n",
        "d_test = pd.read_csv (r'test.data',header=None,delimiter = \"|\")\n",
        "d_test = d_test.reset_index()\n",
        "d_val = pd.read_csv (r'validate.data',header=None,delimiter = \"|\")\n",
        "d_val = d_val.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lLEs07PoeCRD"
      },
      "outputs": [],
      "source": [
        "#rename columns of the dataframes\n",
        "d_train = rename_cols(d_train)\n",
        "d_test = rename_cols(d_test)\n",
        "d_val = rename_cols(d_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EKFxk4VOeFin"
      },
      "outputs": [],
      "source": [
        "#renaming the index column to unique ids\n",
        "d_test = d_test.rename(columns = {'index':\"UniqueIDs\"})\n",
        "d_val = d_val.rename(columns = {'index':\"UniqueIDs\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RdYOR64PeUla"
      },
      "outputs": [],
      "source": [
        "#remove trailing spaces from target word columns\n",
        "d_train['Target_Word'] = d_train.Target_Word.str.replace(' ', '') \n",
        "d_test['Target_Word'] = d_test.Target_Word.str.replace(' ', '') \n",
        "d_val['Target_Word'] = d_val.Target_Word.str.replace(' ', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised WSD**"
      ],
      "metadata": {
        "id": "xHCZuCDc_RIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T4D5KeZurkt0"
      },
      "outputs": [],
      "source": [
        "#set window size\n",
        "#comment when computing for window size N=2\n",
        "N=1\n",
        "#uncomment when computing for window size N=2\n",
        "#N=2\n",
        "\n",
        "#Co-occrrence feature extraction\n",
        "#Function for Feature selection based on window size specified above.\n",
        "def get_features(sentence):\n",
        "    \n",
        "    #Cleaning the sentence\n",
        "    sentence = clean(sentence)\n",
        "    \n",
        "    #splitting the words of the sentence\n",
        "    listofwords = sentence.split()\n",
        "\n",
        "    #Getting the POS for each word and its lemma\n",
        "    listofwords= get_pos_wordnet(listofwords)\n",
        "    \n",
        "    #removing stop words\n",
        "    stop = stopwords.words('english')\n",
        "    listofwords = [x for x in listofwords if x[1] not in stop]   \n",
        "\n",
        "    #fetching the index for first occurence of %%\n",
        "    index=[x[1] for x in listofwords].index('%%')\n",
        "\n",
        "    if index-N>0:\n",
        "        listofwords = listofwords[index-N:index+N+3] \n",
        "        # will list 5 words starting from prev word, %%, target word, %% and next word for N=1\n",
        "    else:\n",
        "        listofwords = listofwords[:index+N+1]\n",
        "\n",
        "    index=[x[1] for x in listofwords].index('%%')\n",
        "    del listofwords[index:index+3]\n",
        "\n",
        "    return listofwords # returns the [[pos, prev word], [pos, next word]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FOCacLOOtE9X"
      },
      "outputs": [],
      "source": [
        "#Function to train separate model per each target word using Prior probabilites and feature probabilities\n",
        "def generate_train_model(d_train , target, smooth = False):\n",
        "\n",
        "    #limiting the training data for words with instances more than 100\n",
        "    d_train[\"num\"] = d_train.groupby(\"Target_Word\")[\"Target_Word\"].cumcount()+1\n",
        "    d_train = d_train.loc[d_train['num'] < 100]\n",
        "    d_train = d_train\n",
        "\n",
        "    new_df_train = d_train.loc[d_train['Target_Word'] == target]\n",
        "    new_df_train = new_df_train.reset_index()\n",
        "    \n",
        "    # to get feature vectors in the form [[pos, prev word], [pos, next word]] and each feature vectors count\n",
        "    new_df_train['FeatureVec'] = new_df_train.swifter.apply(lambda x : get_features(x['Sentence']),axis=1) \n",
        "    #new_df_train['CountofFV']  = new_df_train.swifter.apply(lambda x : len(x['FeatureVec']),axis=1) \n",
        "\n",
        "    #Calculate Prior Probabilities\n",
        "    d_senses = pd.DataFrame(new_df_train.Sense_ID.value_counts())\n",
        "    # each sense id count/total count of all senses for that target word   \n",
        "    d_senses['PriorProb']= d_senses['Sense_ID']/sum(d_senses['Sense_ID'])     \n",
        "    list1 = list(d_senses.index)\n",
        "    list2 = list(d_senses.PriorProb)\n",
        "    priorprob_dict = dict(zip(list1,list2)) # sense id and prior prob\n",
        "    \n",
        "    #number of times the target words appears in a particular sense\n",
        "    prob_word = pd.DataFrame(new_df_train.groupby(by = 'Sense_ID').sum())\n",
        "    prob_word = prob_word.reset_index()\n",
        "    list1 = list(prob_word.Sense_ID)\n",
        "    list2 = list(prob_word.index)\n",
        "    count_target_words = dict(zip(list1,list2)) # sense id and target word count\n",
        "    \n",
        "    #Calculating the occurrences of feature words within a context and returning format pos-word-sense_id:count\n",
        "    train_feature_corpus = new_df_train['FeatureVec'].tolist()\n",
        "    senseid_features_list = list(zip(new_df_train['Sense_ID'].tolist(),train_feature_corpus))\n",
        "    feature_occ_incontext = {}\n",
        "    for temp in senseid_features_list:\n",
        "        for j in temp[1]:\n",
        "            key = j[0]+'-'+j[1]+'-'+str(temp[0])\n",
        "            if key not in feature_occ_incontext:\n",
        "                feature_occ_incontext[key] = 1\n",
        "            else:\n",
        "                feature_occ_incontext[key] = feature_occ_incontext[key]+1\n",
        "    \n",
        "    #Creatimg a dataframe with senseid, word, numerator and denominator for individual feature probability\n",
        "    feature_prob_df = pd.DataFrame(columns=['Sense_ID','Word','Numerator','Denominator']) \n",
        "    for k in feature_occ_incontext.keys():\n",
        "        sense_id = k.split('-')[-1]\n",
        "        word = k.split('-')[:2]\n",
        "        word = \"-\".join(word)\n",
        "\n",
        "        to_append = [sense_id, word, feature_occ_incontext[k], count_target_words[int(sense_id)]]\n",
        "        i = len(feature_prob_df)\n",
        "        feature_prob_df.loc[i] = to_append\n",
        "    \n",
        "    #Calculating the feature probability\n",
        "    if smooth:\n",
        "      #Getting the vocabulary of words\n",
        "      V = len(feature_occ_incontext.keys())\n",
        "      #uncomment this line for lamda =1\n",
        "      #lamda = 1\n",
        "      #comment this line for lamda =1\n",
        "      lamda = 0.001\n",
        "      #lamda = 0.01\n",
        "      feature_prob_df['Probability'] = (feature_prob_df['Numerator']+lamda) / (feature_prob_df['Denominator']+(V*lamda))\n",
        "    else:\n",
        "      feature_prob_df['Probability'] = (feature_prob_df['Numerator']) / (feature_prob_df['Denominator'])\n",
        "\n",
        "    feature_prob_df['Word_Sense_ID'] = feature_prob_df['Word']+ '-' +feature_prob_df['Sense_ID']\n",
        "    training_dict = dict(zip(feature_prob_df['Word_Sense_ID'], feature_prob_df['Probability']))\n",
        "    return training_dict, priorprob_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fcQII8SoxMCa"
      },
      "outputs": [],
      "source": [
        "#uncomment below when combine training and validation, to run the model on test dataset\n",
        "#d_train = d_train.append(d_val)\n",
        "#d_train = d_train.reset_index()\n",
        "#d_train = d_train.rename(columns = {'index':\"UniqueIDs\"})\n",
        "\n",
        "#uncomment below line when using the validation data for testing\n",
        "d_test = d_val\n",
        "\n",
        "target_words_unique = d_test['Target_Word'].value_counts()\n",
        "target_words_unique = pd.DataFrame(target_words_unique)\n",
        "target_words_unique = target_words_unique.reset_index()\n",
        "target_words_unique.columns=['Words','Count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5UT-FVxlxN2S"
      },
      "outputs": [],
      "source": [
        "target_words = target_words_unique.Words.tolist()\n",
        "predictions = pd.DataFrame(columns=['PredictedSenseId','Sentence','TargetWord','UniqueIDs', 'ActualSenseId'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCC_zDofxQWy"
      },
      "outputs": [],
      "source": [
        "counter=0\n",
        "for target_word in target_words:\n",
        "    print(\"Processed \", counter,\"Target words out of \", len(target_words))    \n",
        "    counter = counter+1\n",
        "\n",
        "    #Fetching the test instances for the target word from test data\n",
        "    test_inst = d_test.loc[d_test['Target_Word'] == target_word]\n",
        "    test_inst = test_inst.reset_index()\n",
        "\n",
        "    #Generate the model for every target word, along with its prior probability with add-lambda smoothing\n",
        "    training_model , priorprob_dict = generate_train_model(d_train, target_word, smooth = True)\n",
        "\n",
        "    #uncomment when we want to generate the model for every target word with no Smoothing\n",
        "    #training_model , priorprob_dict = generate_train_model(df_train, target_word) # throws division by zero error\n",
        "\n",
        "    #Fetching test instances unique ids and actual sense ids\n",
        "    ids = test_inst['UniqueIDs'].tolist()\n",
        "    actual_sense_id = test_inst['Sense_ID'].tolist()\n",
        "\n",
        "    j=0\n",
        "    for sent in test_inst['Sentence']:\n",
        "        #get the feature vectors for each test sentences\n",
        "        eachsent = sent\n",
        "        eachsent_fv = get_features(eachsent) \n",
        "        \n",
        "        results = {}\n",
        "        #Fetching unique sense ids from training data\n",
        "        sense_ids = priorprob_dict.keys() \n",
        "\n",
        "        for sense_id in sense_ids:\n",
        "            prob_vals = []\n",
        "            listoffv = []\n",
        "            for fv in eachsent_fv:\n",
        "                test_fv = fv[0]+'-'+fv[1]+'-'+str(sense_id) #pos-word-senseid from test sentence\n",
        "                if test_fv in training_model:\n",
        "                    prob_vals.append(training_model[test_fv]) #Individual probabilities for each features\n",
        "                    listoffv.append(test_fv) #Word_Sense_id\n",
        "\n",
        "            #Calculating probability for each sense for a target word\n",
        "            results[sense_id] = priorprob_dict[sense_id] * np.prod(prob_vals)\n",
        "\n",
        "        #Get the max probability sense id\n",
        "        max_val_senseid = max(results.items(), key=operator.itemgetter(1))[0]\n",
        "        to_append = [max_val_senseid, sent, target_word, ids[j], actual_sense_id[j]]\n",
        "        j = j+1\n",
        "        length = len(predictions)\n",
        "        predictions.loc[length] = to_append\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without smoothing the process throws a division by zero error."
      ],
      "metadata": {
        "id": "myG4W3q0KlCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For lambda = 1 & N=1**\n",
        "\n",
        "Commented the lambda = 0.01 and made it to lambda = 1, for validation data with N=1 as window size"
      ],
      "metadata": {
        "id": "oDZaIQKWugdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the accuracy\n",
        "val_predictions_l1_N1 = predictions\n",
        "\n",
        "val_predictions_l1_N1['Acc'] = val_predictions_l1_N1.ActualSenseId == val_predictions_l1_N1.PredictedSenseId\n",
        "accuracy = val_predictions_l1_N1['Acc'].value_counts() / len(val_predictions_l1_N1['Acc'])\n",
        "print(\"Validation Data accuracy is %s \",str(accuracy[1])) #53.59%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCYOpGi-uft3",
        "outputId": "bafbd807-8e90-46a2-fd9a-b0cc114aa020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Data accuracy is %s  0.5359056806002144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data into pickle files\n",
        "val_predictions_l1_N1.to_pickle('Final_Predictions_val_lambda1.pkl')\n",
        "files.download('Final_Predictions_val_lambda1.pkl')"
      ],
      "metadata": {
        "id": "ktaraM-qzn8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting into csv files\n",
        "val_predictions_l1_N1.to_csv(r'Validation_predictions_lambda_1.csv')"
      ],
      "metadata": {
        "id": "hsT7pT9pzpSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**For lambda = 0.001 & N=1**\n",
        "\n",
        "Predictons when lambda = 0.001 and N window for feature vector selection is 1"
      ],
      "metadata": {
        "id": "OaKc3vvTsMlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c6a59c-b426-4e1c-de81-fc2feabffc1b",
        "id": "AsE3S2FOsMlU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Data accuracy is %s  0.8177920685959271\n"
          ]
        }
      ],
      "source": [
        "val_predictions_l0001_N1 = predictions\n",
        "\n",
        "#Checking the accuracy \n",
        "val_predictions_l0001_N1['Acc'] = val_predictions_l0001_N1.ActualSenseId == val_predictions_l0001_N1.PredictedSenseId\n",
        "accuracy = val_predictions_l0001_N1['Acc'].value_counts()/len(val_predictions_l0001_N1['Acc'])\n",
        "print(\"Validation Data accuracy is %s \",str(accuracy[1])) # 81.78%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data into pickle files\n",
        "val_predictions_l0001_N1.to_pickle('Final_Predictions_val_lambda0001.pkl')\n",
        "files.download('Final_Predictions_val_lambda0001.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fSwTqcrJsMlU",
        "outputId": "c0250bd4-dd88-4744-cefa-32707377c922"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2a0b87a7-8481-4b77-94a9-2a6566ec0ace\", \"Final_Predictions_val_lambda0001.pkl\", 636562)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data into csv\n",
        "val_predictions_l0001_N1.to_csv(r'Validation_predictions_lambda_l0001_N1.csv')"
      ],
      "metadata": {
        "id": "IKNs8-HQsMlV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For lambda = 0.01 & N=1**\n",
        "\n",
        "Predictons when lambda = 0.01 and N window for feature vector selection is 1"
      ],
      "metadata": {
        "id": "yPjnEqjEsLTv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTqr-FQsxTDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524d2ad7-5b5e-4592-bcf0-c9b6c3e15cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Data accuracy is %s  0.8070739549839229\n"
          ]
        }
      ],
      "source": [
        "val_predictions_l001_N1 = predictions\n",
        "\n",
        "#Checking the accuracy \n",
        "val_predictions_l001_N1['Acc'] = val_predictions_l001_N1.ActualSenseId == val_predictions_l001_N1.PredictedSenseId\n",
        "accuracy = val_predictions_l001_N1['Acc'].value_counts()/len(val_predictions_l001_N1['Acc'])\n",
        "print(\"Validation Data accuracy is %s \",str(accuracy[1])) # 80.70%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data into pickle files\n",
        "val_predictions_l001_N1.to_pickle('Final_Predictions_val_lambda001.pkl')\n",
        "files.download('Final_Predictions_val_lambda001.pkl')"
      ],
      "metadata": {
        "id": "ZIwceGuUtCUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting data into csv\n",
        "val_predictions_l001_N1.to_csv(r'Validation_predictions_lambda_001.csv')"
      ],
      "metadata": {
        "id": "0CskaxH5tDa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For lambda= 0.01 and N=2**\n",
        "\n",
        "Lambda = 0.01 gives us better accuracy of 81% than lambda = 1 which gives an accuracy of 54% \n",
        "\n",
        "Before moving to test data, we will check if N =2 as window size for feature selection improves the accuracy or not. Commented N=1 in this case."
      ],
      "metadata": {
        "id": "1ZIeR8LoF4k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions_l001_N2 = predictions\n",
        "\n",
        "#Checking the accuracy \n",
        "val_predictions_l001_N2['Acc']= val_predictions_l001_N2.ActualSenseId == val_predictions_l001_N2.PredictedSenseId\n",
        "accuracy = val_predictions_l001_N2['Acc'].value_counts()/len(val_predictions_l001_N2['Acc'])\n",
        "print(\"Validation Data accuracy is %s \",str(accuracy[1])) # 74.17%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeRmb3b3tL2S",
        "outputId": "56a24eed-fa90-480e-c61f-f74269e65bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Data accuracy is %s  0.7416934619506966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting into a pickle file\n",
        "val_predictions_l001_N2.to_pickle('Final_Predictions_Val_lambda001_N2.pkl')\n",
        "files.download('Final_Predictions_Val_lambda001_N2.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_1SUHqCKtMP0",
        "outputId": "817ff581-79a9-4121-f6f5-20abb367e139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69de5a74-8ec8-4302-914c-322cc9c44e31\", \"Final_Predictions_Val_lambda001_N2.pkl\", 635516)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting into a csv file\n",
        "val_predictions_l001_N2.to_csv(r'Final_Predictions_Val_lambda001_N2.csv')"
      ],
      "metadata": {
        "id": "PkDUrBVAtN45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**For lambda=0.001 and N=1 for test data predictions**\n",
        "\n",
        "So we will be using lambda = 0.001 with N=1 for predicting senses for test data. We will also be using the train+validation data as training data in this case."
      ],
      "metadata": {
        "id": "sy13NQhYtIsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_l0001_N1 = predictions"
      ],
      "metadata": {
        "id": "N0lYIfwCGWhu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract data into pickle file\n",
        "test_predictions_l0001_N1.to_pickle('Final_Predictions_test.pkl')\n",
        "files.download('Final_Predictions_test.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "w6HjpV5fGYMF",
        "outputId": "ca05e438-45d5-4913-f00a-7b7ea56f9677"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6dd0cd63-f4c0-4cd6-951a-0e390641597c\", \"Final_Predictions_test.pkl\", 2672562)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract into a csv file\n",
        "test_predictions_l0001_N1.to_csv(r'Final_Predictions_test.csv')"
      ],
      "metadata": {
        "id": "tqx4iTf8GaQJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BASELINE MODEL**"
      ],
      "metadata": {
        "id": "2F2uGWcI9Xwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ-mttLdejTF"
      },
      "outputs": [],
      "source": [
        "#For computing baseline accuracy, we use the Validation data\n",
        "d_baseline = d_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1H_7fj42e9zU",
        "outputId": "222b627d-a6e0-405f-b0a3-5fa917083aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     UniqueIDs Target_Word  Sense_ID  \\\n",
              "0            0   capital.n         1   \n",
              "1            1   capital.n         1   \n",
              "2            2   capital.n         1   \n",
              "3            3   capital.n         1   \n",
              "4            4   capital.n         1   \n",
              "..         ...         ...       ...   \n",
              "928        928      keep.v         1   \n",
              "929        929      keep.v         4   \n",
              "930        930      keep.v         1   \n",
              "931        931  maintain.v         1   \n",
              "932        932  maintain.v         1   \n",
              "\n",
              "                                              Sentence  \n",
              "0     The firm 's capital , moreover , has n't grow...  \n",
              "1     This observation leads us to another piece of...  \n",
              "2     `` It 's a problem that clearly has to be res...  \n",
              "3     Drexel this year eliminated its retail or ind...  \n",
              "4     Municipals Rebounding stocks and weaker Treas...  \n",
              "..                                                 ...  \n",
              "928   Mr. Kaye says he has paid more than $ 70,000 ...  \n",
              "929   Although the report , which was released befo...  \n",
              "930   Fed Chairman Greenspan was surprised by both ...  \n",
              "931   Overall , though , the South and West still o...  \n",
              "932   While population at Fort Garry increased rapi...  \n",
              "\n",
              "[933 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81ef71a4-2765-447d-a15c-7a76933cfc9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UniqueIDs</th>\n",
              "      <th>Target_Word</th>\n",
              "      <th>Sense_ID</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>capital.n</td>\n",
              "      <td>1</td>\n",
              "      <td>The firm 's capital , moreover , has n't grow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>capital.n</td>\n",
              "      <td>1</td>\n",
              "      <td>This observation leads us to another piece of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>capital.n</td>\n",
              "      <td>1</td>\n",
              "      <td>`` It 's a problem that clearly has to be res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>capital.n</td>\n",
              "      <td>1</td>\n",
              "      <td>Drexel this year eliminated its retail or ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>capital.n</td>\n",
              "      <td>1</td>\n",
              "      <td>Municipals Rebounding stocks and weaker Treas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>928</td>\n",
              "      <td>keep.v</td>\n",
              "      <td>1</td>\n",
              "      <td>Mr. Kaye says he has paid more than $ 70,000 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>929</td>\n",
              "      <td>keep.v</td>\n",
              "      <td>4</td>\n",
              "      <td>Although the report , which was released befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>930</td>\n",
              "      <td>keep.v</td>\n",
              "      <td>1</td>\n",
              "      <td>Fed Chairman Greenspan was surprised by both ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>931</td>\n",
              "      <td>maintain.v</td>\n",
              "      <td>1</td>\n",
              "      <td>Overall , though , the South and West still o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>932</td>\n",
              "      <td>maintain.v</td>\n",
              "      <td>1</td>\n",
              "      <td>While population at Fort Garry increased rapi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>933 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81ef71a4-2765-447d-a15c-7a76933cfc9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81ef71a4-2765-447d-a15c-7a76933cfc9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81ef71a4-2765-447d-a15c-7a76933cfc9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "d_baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jrIr0LGekHQ"
      },
      "outputs": [],
      "source": [
        "#retrieve list of unique target words\n",
        "target_words_unique = d_baseline['Target_Word'].value_counts()\n",
        "target_words_unique = pd.DataFrame(target_words_unique)\n",
        "target_words_unique = target_words_unique.reset_index()\n",
        "target_words_unique.columns = ['Words','Count']\n",
        "targetwordlist = target_words_unique.Words.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvyeaM4Sxr0u"
      },
      "outputs": [],
      "source": [
        "target_words_unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZLbkEdmfSEi"
      },
      "outputs": [],
      "source": [
        "### BASELINE MODEL ###\n",
        "#creating a table to store predictions\n",
        "predictions = pd.DataFrame(columns=['PredictedSenseId','Sentence','ActualSenseId','UniqueIDs'])\n",
        "counter=0\n",
        "\n",
        "# Baseline Model for each target word  --> Most frequent sense with highest P(s) => Random Guess\n",
        "for target_word in targetwordlist:\n",
        "    print(\"Processed \", counter,\"Target words out of \", len(targetwordlist))    \n",
        "    counter = counter+1\n",
        "\n",
        "    #Fetching test instances from df_baseline for that target word            \n",
        "    test_inst = d_baseline.loc[d_baseline['Target_Word'] == target_word]\n",
        "    test_inst = test_inst.reset_index()\n",
        "                    \n",
        "    ids = test_inst['UniqueIDs'].tolist()\n",
        "    actual_senses = test_inst['Sense_ID'].tolist()\n",
        "                    \n",
        "    #Fetching train instances from df_train for that target word\n",
        "    train_inst = d_train.loc[d_train['Target_Word'] == target_word]\n",
        "\n",
        "    #Fetching the different sense ids for this targte word from training data\n",
        "    senses = pd.DataFrame(train_inst.Sense_ID.value_counts())\n",
        "    senses = senses.reset_index()\n",
        "\n",
        "    #assign the most frequent sense_id as a prediction of the target word\n",
        "    pred = senses[senses.Sense_ID == senses.Sense_ID.max()]['index'].tolist()[0]  \n",
        "\n",
        "    i=0\n",
        "    for sent in test_inst['Sentence']:\n",
        "        to_append = [pred, sent,actual_senses[i],ids[i]]\n",
        "        i=i+1\n",
        "        length = len(predictions)\n",
        "        predictions.loc[length] = to_append\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "chsJrMUMrQEc",
        "outputId": "c2217417-33e6-4aa7-cb7d-7d092d621c73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PredictedSenseId                                           Sentence  \\\n",
              "0                  1   Avions Marcel Dassault-Breguet Aviation S.A. ...   \n",
              "1                  1   Roger Rosenblatt , editor of U.S. News & Worl...   \n",
              "2                  1   Asked to compare her visit to Mr. Mosbacher '...   \n",
              "3                  1   Pension funds , insurers and other behemoths ...   \n",
              "4                  1   Freeport-McMoRan Inc. said a temporary cessat...   \n",
              "..               ...                                                ...   \n",
              "928                1   This may be true whether the farm is owned or...   \n",
              "929                1   But a lawyer for Triland Investment Group , t...   \n",
              "930                1   `` I was buying at the close ( Friday ) and I...   \n",
              "931                1   The location was disclosed as the U.S. began ...   \n",
              "932                1   The purpose of this fourth voyage was clear ....   \n",
              "\n",
              "    ActualSenseId UniqueIDs  \n",
              "0               1       377  \n",
              "1               1       378  \n",
              "2               1       379  \n",
              "3               1       380  \n",
              "4               2       381  \n",
              "..            ...       ...  \n",
              "928             2       288  \n",
              "929             1       112  \n",
              "930             1       516  \n",
              "931             1       572  \n",
              "932             2       812  \n",
              "\n",
              "[933 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e80e25c4-e1c4-44ba-9712-5a7cbfb59ef2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PredictedSenseId</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>ActualSenseId</th>\n",
              "      <th>UniqueIDs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Avions Marcel Dassault-Breguet Aviation S.A. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Roger Rosenblatt , editor of U.S. News &amp; Worl...</td>\n",
              "      <td>1</td>\n",
              "      <td>378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Asked to compare her visit to Mr. Mosbacher '...</td>\n",
              "      <td>1</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Pension funds , insurers and other behemoths ...</td>\n",
              "      <td>1</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Freeport-McMoRan Inc. said a temporary cessat...</td>\n",
              "      <td>2</td>\n",
              "      <td>381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>1</td>\n",
              "      <td>This may be true whether the farm is owned or...</td>\n",
              "      <td>2</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>1</td>\n",
              "      <td>But a lawyer for Triland Investment Group , t...</td>\n",
              "      <td>1</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>1</td>\n",
              "      <td>`` I was buying at the close ( Friday ) and I...</td>\n",
              "      <td>1</td>\n",
              "      <td>516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>1</td>\n",
              "      <td>The location was disclosed as the U.S. began ...</td>\n",
              "      <td>1</td>\n",
              "      <td>572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>1</td>\n",
              "      <td>The purpose of this fourth voyage was clear ....</td>\n",
              "      <td>2</td>\n",
              "      <td>812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>933 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80e25c4-e1c4-44ba-9712-5a7cbfb59ef2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e80e25c4-e1c4-44ba-9712-5a7cbfb59ef2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e80e25c4-e1c4-44ba-9712-5a7cbfb59ef2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "baseline_predictions = predictions\n",
        "baseline_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7OQcpiZraqi",
        "outputId": "38dcf41e-a651-4f47-a2ff-9c44644461b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy is %s  0.8113612004287245\n"
          ]
        }
      ],
      "source": [
        "#Add a new column for measuring Accuracy\n",
        "baseline_predictions['Accuracy'] = baseline_predictions.PredictedSenseId == baseline_predictions.ActualSenseId\n",
        "acc = baseline_predictions['Accuracy'].value_counts()/len(baseline_predictions['Accuracy'])\n",
        "print(\"Baseline accuracy is %s \",str(acc[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Accuracy of Baseline Model = 81.13%*"
      ],
      "metadata": {
        "id": "9a1KKsI9-Uoa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}